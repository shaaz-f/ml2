{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04eiOwKQsqH1"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZLD9Ut6hlzOj"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Import necessary libraries\n",
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from math import floor\n",
        "import copy\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import TypeVar, Generic\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TceMijclm88H"
      },
      "source": [
        "# !!!IMPORTANT!!!\n",
        "Insert your details below. You should see a green checkmark.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oLmk6yxnlzKv"
      },
      "outputs": [],
      "source": [
        "# Input student details (replace these with actual input values)\n",
        "student = {\n",
        "    \"name\": \"Shaaz Feerasta\",                    # Replace with your name\n",
        "    \"email\": \"feerasta@ualberta.ca\",       # Replace with your email\n",
        "    \"ccid\": \"feerasta\",                    # Replace with your CCID\n",
        "    \"idnumber\": 1704756,                  # Replace with your ID number\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gbrrIaTmlzGn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome Shaaz Feerasta! ✅\n"
          ]
        }
      ],
      "source": [
        "# Define the default and user-provided student dictionaries\n",
        "def_student = {\n",
        "    \"name\": \"Shaaz Feerasta\",\n",
        "    \"email\": \"feerasta@ualberta.ca\",\n",
        "    \"ccid\": \"feerasta\",\n",
        "    \"idnumber\": 1704756\n",
        "}\n",
        "\n",
        "\n",
        "# Validation checks\n",
        "assert set(def_student.keys()) == set(student.keys()),   \"You don't have all the right entries! Make sure you have `name`, `email`, `ccid`, `idnumber`. ❌\"\n",
        "assert not any(value == \"\" for value in student.values()), \"You haven't filled in all your details! No field should be empty. ❌\"\n",
        "assert all(isinstance(student[k], type(def_student[k])) for k in def_student),    \"Your types seem to be off: `name::String`, `email::String`, `ccid::String`, `idnumber::Int`. ❌\"\n",
        "assert student[\"email\"].endswith(\"@ualberta.ca\"), \"Your email must end with '@ualberta.ca'. ❌\"\n",
        "\n",
        "print(f\"Welcome {student['name']}! ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxbdCYpUpONn"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_GaNn8upRlf"
      },
      "source": [
        "## The model interface\n",
        "- AbstractModel: This is an abstract type which is used to derive all the model types in this assignment.\n",
        "\n",
        "- predict: This takes a matrix of samples and returns the prediction doing the proper data transforms.\n",
        "\n",
        "- get_features: This transforms the features according to the non-linear transform of the model (which is the identity for linear).\n",
        "\n",
        "- update_transform: This \"trains\" the transform. Using the data provided we update the PCA or Kernel prototypes used according to the strategy.\n",
        "\n",
        "- get_linear_model: All models are based on a linear model with transformed features, and thus have a linear model.\n",
        "\n",
        "- copy: This returns a new copy of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCqOZs5FraMH"
      },
      "source": [
        "\tAbstractModel\n",
        "\n",
        "Used as the root for all models in this notebook. We provide a helper `predict` function for `AbstractVectors` which transposes the features to a row vector. We also provide a default `update_transform` which does nothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "93sBPPPprwQl"
      },
      "outputs": [],
      "source": [
        "class AbstractModel(ABC):\n",
        "    @abstractmethod\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Abstract method for prediction. Subclasses must implement this.\n",
        "        \"\"\"\n",
        "        pass\n",
        "    def update_transform(self, *args):\n",
        "        \"\"\"\n",
        "        Default update_transform method which does nothing.\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LIKC-xluly6a"
      },
      "outputs": [],
      "source": [
        "# Helper function\n",
        "def predict(model, x):\n",
        "    \"\"\"\n",
        "    Helper predict function for AbstractModel.\n",
        "    Transposes the input vector and takes the first element of the result.\n",
        "    \"\"\"\n",
        "    if not isinstance(model, AbstractModel):\n",
        "        raise TypeError(\"model must be an instance of AbstractModel.\")\n",
        "\n",
        "    # Convert x to a row vector and call the model's predict\n",
        "    x_row = np.array(x).reshape(1, -1)  # Transpose to row vector\n",
        "    return model.predict(x_row)[0]  # Return the first element of the result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJeFqaEILGU0"
      },
      "source": [
        "## Linear Model\n",
        "\n",
        "\n",
        "We define a linear model as a linear map:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\mathbf{x} \\mathbf{w}\n",
        "$$\n",
        "\n",
        "$\\mathbf{x}$ is a row vector. This row vector comes from data matrix $\\mathbf{X}$ of size $(\\text{samples}, \\text{features})$. We can also write the linear model as\n",
        "\n",
        "$$\n",
        "\\hat{Y} = \\mathbf{X} \\mathbf{w}\n",
        "$$\n",
        "\n",
        "To simplify the `predict` function, we provide a utility function that ensures a `Vector` (interpreted as a column vector) is transformed into a row vector (or a $1 \\times n$ matrix). This way, you can call `predict(model, np.random.rand(10))` without worrying about whether \\(x\\) is a column or row vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kt51EUmEMGQo"
      },
      "outputs": [],
      "source": [
        "class LinearModel:\n",
        "    \"\"\"\n",
        "    A linear model that maps inputs to outputs using a weight matrix.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features=1):\n",
        "        # Initialize the weight matrix with zeros (feature_size x output_size)\n",
        "        self.W = np.zeros((in_features, out_features))\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Perform a linear transformation: Ŷ = np.dot(X, W)\n",
        "        \"\"\"\n",
        "        if X.ndim == 1:\n",
        "          X = X.reshape(1, -1)\n",
        "\n",
        "        return X@self.W\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"\n",
        "        Create a copy of the current model.\n",
        "        \"\"\"\n",
        "        new_model = LinearModel(self.W.shape[0], self.W.shape[1])\n",
        "        new_model.W = self.W.copy()\n",
        "        return new_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUeffoWBNO7d"
      },
      "source": [
        "\n",
        "## Kernel Functions for Similarity Features\n",
        "\n",
        "In this section, we will be defining the components to use kernel functions as similarity features to transform our input data. To implement the `KernelModel`, we need to implement a helper function and some similarity functions to use with the model.\n",
        "\n",
        "- `get_features`\n",
        "- `cosine_similarity`\n",
        "- `RBF`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Sk-akguGNOWx"
      },
      "outputs": [],
      "source": [
        "class KernelModel:\n",
        "    \"\"\"\n",
        "    This model transforms the features and then uses a linear model to learn.\n",
        "    The structure has three components:\n",
        "    `kern` is the kernel function used to build the features.\n",
        "    \"\"\"\n",
        "    def __init__(self, kern, prototypes=None, out=1, prototype_selection_strategy=None):\n",
        "        if callable(kern):\n",
        "            # Check that the kernel function produces a float64 result when applied to random data\n",
        "            assert isinstance(kern(np.random.rand(5), np.random.rand(5)), float), \\\n",
        "                \"Kernel function must return a float64 result.\"\n",
        "\n",
        "\n",
        "        # If prototypes are provided, initialize the model with prototypes\n",
        "        if prototypes is not None:\n",
        "            assert len(prototypes) > 0, \"Prototypes list must have at least one element.\"\n",
        "            self.kern = kern\n",
        "            self.prototype_selection_strategy = prototype_selection_strategy\n",
        "            self.prototypes = prototypes\n",
        "            self.model = LinearModel(len(prototypes[1]), out)\n",
        "\n",
        "        else:\n",
        "            # If no prototypes, initialize a blank kernel model\n",
        "            self.kern = kern\n",
        "            self.prototype_selection_strategy = prototype_selection_strategy\n",
        "            self.prototypes = []  # Empty prototypes initially\n",
        "            self.model = LinearModel(0, out)\n",
        "\n",
        "    def get_linear_model(self):\n",
        "        \"\"\"\n",
        "        Return the linear model component.\n",
        "        \"\"\"\n",
        "        return self.model\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"\n",
        "        Create a copy of the current KernelModel.\n",
        "        \"\"\"\n",
        "        new_kernel_model = KernelModel(\n",
        "            self.kern,\n",
        "            list(self.prototypes),\n",
        "            self.model.W.shape[1],\n",
        "            self.prototype_selection_strategy\n",
        "        )\n",
        "        new_kernel_model.model = self.model.copy()\n",
        "        return new_kernel_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7Am0FnVPkZk"
      },
      "source": [
        "### `get_features`\n",
        "The first function you need to implement is `get_features` which transforms a matrix of features `X` with dimensions `(num_samples, features)` according to the kernel function $K$ and the collection of $N$ prototypes $C = \\{\\mathbf{c}_1, \\mathbf{c}_2, \\ldots, \\mathbf{c}_N\\}$. For each sample $\\mathbf{x}$, the new feature vector $\\tilde{\\mathbf{x}}$ is of dimension $N$ and is constructed using\n",
        "\n",
        "$$\n",
        "\\tilde{x}_i = K(\\mathbf{x}, \\mathbf{c}_i)\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bmDdu7oLQjf2"
      },
      "outputs": [],
      "source": [
        "def get_features(km, X):\n",
        "    \"\"\"\n",
        "    Transforms the matrix of features X with dimensions (num_samples, features)\n",
        "    using the kernel function and the collection of prototypes.\n",
        "\n",
        "    Args:\n",
        "    - km: KernelModel instance containing the kernel function and prototypes.\n",
        "    - X: Matrix of features (num_samples, num_features).\n",
        "\n",
        "    Returns:\n",
        "    - Transformed features matrix (num_samples, len(prototypes)).\n",
        "    \"\"\"\n",
        "    kern, prototypes = km.kern, km.prototypes\n",
        "\n",
        "    # Create an empty matrix to store the new features\n",
        "    new_features = np.zeros((X.shape[0], len(prototypes)))\n",
        "\n",
        "    # BEGIN SOLUTION\n",
        "    # Fill the new features matrix with kernel function results\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(len(prototypes)):\n",
        "            new_features[i][j] = kern(X[i], prototypes[j])\n",
        "    # END SOLUTION\n",
        "\n",
        "    return new_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dfvFLMlER07z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed Features:\n",
            " [[ 5. 11.]\n",
            " [11. 25.]]\n",
            "Test passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# #####################\n",
        "# Test Block\n",
        "# #####################\n",
        "\n",
        "# Example kernel function\n",
        "def simple_kernel(x, c):\n",
        "    return np.dot(x, c)  # A simple dot product kernel\n",
        "\n",
        "\n",
        "\n",
        "km = KernelModel(kern=simple_kernel, prototypes=[np.array([1, 2]), np.array([3, 4])])\n",
        "\n",
        "# Example input matrix X\n",
        "X = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Get the transformed features\n",
        "features = get_features(km, X)\n",
        "\n",
        "print(\"Transformed Features:\\n\", features)\n",
        "\n",
        "\n",
        "assert np.allclose(features, np.array([[5, 11], [11, 25]]), 0.1), \"Test Failed!'. ❌\"\n",
        "\n",
        "print(f\"Test passed! ✅\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8_bEYsQsfnR"
      },
      "source": [
        "Notice how `get_features` interacts with predict.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WwXen-uZSkwa"
      },
      "outputs": [],
      "source": [
        "def predict(self, x):\n",
        "        \"\"\"\n",
        "        Predicts the output for the KernelModel using the transformed features.\n",
        "\n",
        "        Args:\n",
        "        - km: KernelModel instance containing the kernel function, prototypes, and the model.\n",
        "        - x: Matrix of features (num_samples, num_features).\n",
        "\n",
        "        Returns:\n",
        "        - Predictions based on the kernel-transformed features.\n",
        "        \"\"\"\n",
        "        # Transform the input features using the kernel function\n",
        "        transformed_features = get_features(self, x)\n",
        "\n",
        "        # Use the linear model to predict the output based on the transformed features\n",
        "        return (km.model.predict(transformed_features))\n",
        "\n",
        "# Add the method to MyClass\n",
        "KernelModel.predict = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6NQWb4EpVOVi"
      },
      "outputs": [],
      "source": [
        "def update_transform(km, X, Y):\n",
        "    \"\"\"\n",
        "    Updates the kernel model by selecting prototypes and adjusting the linear model.\n",
        "\n",
        "    Args:\n",
        "    - km: KernelModel instance containing the kernel function, prototype selection strategy, and model.\n",
        "    - X: Matrix of features (num_samples, num_features).\n",
        "    - Y: Vector of target values (num_samples,).\n",
        "\n",
        "    Updates the KernelModel prototypes and model based on the given data.\n",
        "    \"\"\"\n",
        "    # If nothing, just use the prototypes that already exist.\n",
        "    try:\n",
        "      css = km.prototype_selection_strategy\n",
        "      prototypes = select_prototypes(css, km.kern, X, Y)\n",
        "\n",
        "        # Update the prototypes and the linear model\n",
        "      km.prototypes = prototypes\n",
        "      km.model = LinearModel(len(prototypes), km.model.W.shape[1])\n",
        "\n",
        "    except:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTUlYWLCVbBz"
      },
      "source": [
        "### `cosine_similarity`\n",
        "The cosine similarity measures the angle between two vectors. It is defined as\n",
        "\n",
        "$$\n",
        "\\frac{\\langle x, c \\rangle}{\\vert\\vert x \\vert\\vert_2 \\vert\\vert c \\vert\\vert_2}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jbwccRmfVdy5"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity():\n",
        "    \"\"\"\n",
        "    Returns a function that calculates the cosine similarity between two vectors.\n",
        "    \"\"\"\n",
        "    def similarity(x, c):\n",
        "        \"\"\"\n",
        "        Calculates the cosine similarity between two vectors.\n",
        "\n",
        "        Args:\n",
        "        - x: First vector (numpy array).\n",
        "        - c: Second vector (numpy array).\n",
        "\n",
        "        Returns:\n",
        "        - Cosine similarity between the vectors.\n",
        "        \"\"\"\n",
        "\n",
        "        # BEGIN SOLUTION\n",
        "        return np.dot(x, c)/(np.linalg.norm(x, 2) * np.linalg.norm(c, 2))\n",
        "        # END SOLUTION\n",
        "\n",
        "    return similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gMRiRgRzV5pu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# #####################\n",
        "# Test Block\n",
        "# #####################\n",
        "\n",
        "# Test cosine similarity with two vectors of ones\n",
        "\n",
        "assert np.allclose(cosine_similarity()(np.ones(5), np.ones(5)), 1), \"Test Failed! ❌\"\n",
        "\n",
        "print(f\"Test passed! ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L167cTDTWTDG"
      },
      "source": [
        "### `RBF`\n",
        "The RBF kernel is widely used in kernel regression and has many appealing properties. Check the Fixed Representations section of the notes for how to implement this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RMWRRUreWoao"
      },
      "outputs": [],
      "source": [
        "def RBF(σ):\n",
        "    \"\"\"\n",
        "    Returns a function that calculates the RBF kernel similarity between two vectors.\n",
        "\n",
        "    Args:\n",
        "    - σ: The standard deviation (σ) for the RBF kernel.\n",
        "\n",
        "    Returns:\n",
        "    - A function that takes two vectors and returns the RBF similarity.\n",
        "    \"\"\"\n",
        "    def similarity(x, c):\n",
        "        # BEGIN SOLUTION\n",
        "        return np.exp(-(np.linalg.norm(x-c)**2/(2*σ**2)))\n",
        "        # END SOLUTION\n",
        "\n",
        "    return similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WX86PQJHXL6X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# #####################\n",
        "# Test Block\n",
        "# #####################\n",
        "\n",
        "\n",
        "assert np.isclose(RBF(0.1)(np.ones(5), np.ones(5)), 1.0), \"First Test Failed! Check your RBF implementation. ❌\"\n",
        "assert np.isclose(RBF(1.0)(np.ones(5), np.zeros(5)), 0.08208499862389876), \"Second Test Failed! Check your RBF implementation. ❌\"\n",
        "\n",
        "print(f\"Tests passed! ✅\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1QFCMRFQYNuU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# #####################\n",
        "# Test Block\n",
        "# #####################\n",
        "\n",
        "n = 5\n",
        "rng = np.random.default_rng(10)\n",
        "\n",
        "# 10 prototypes with dimensions 5\n",
        "km = KernelModel(cosine_similarity(), [rng.random(n) for _ in range(10)], 1)\n",
        "\n",
        "X = rng.random((7, n))\n",
        "\n",
        "# Define the feature function gf\n",
        "gf = lambda x: [km.kern(x, c) for c in km.prototypes]\n",
        "\n",
        "# Generate features using list comprehensions, transposing the result for each row of X\n",
        "feats = np.vstack([gf(x) for x in X])\n",
        "feats_2 = get_features(km, X)\n",
        "feats_3 = np.vstack([get_features(km, x.reshape(1, -1)) for x in X])\n",
        "feats_4 = np.vstack([get_features(km, X[i:i+1, :]) for i in range(X.shape[0])])\n",
        "\n",
        "# Test if the features are approximately equal and not all zeros\n",
        "\n",
        "assert np.allclose(feats, feats_2) and np.allclose(feats, feats_3) and np.allclose(feats, feats_4), \"Values are not approximately equal! ❌\"\n",
        "assert not np.all(feats == 0.0), \"All values are zero! ❌\"\n",
        "\n",
        "print(f\"Test passed! ✅\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-CNitKakWkL"
      },
      "source": [
        "# Learning\n",
        "\n",
        "In this section, you will be implementing Lasso regression. We provide implementations of ordinary least squares (OLS) and ridge regression as examples for how the interface works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6xpTgqOkZ_Y"
      },
      "source": [
        "## Recap: OLS, Ridge, and Lasso\n",
        "\n",
        "Before we get into gradient descent, lets review OLS and two common regularization techniques. The first, Ridge, uses $p=2$ (the $\\ell_2$ norm), and you implemented this in Assignment 1. We provide the implementation here, since you do not need to do it again. The second, Lasso, is for regularization when $p=1$ (the $\\ell_1$ norm). You will be completing this implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q38a5ushkg3M"
      },
      "source": [
        "## Ridge\n",
        "\n",
        "Remember ridge regression corresponds to L2 regularization with the cost function\n",
        "\n",
        "$$\n",
        "c(\\mathbf{w}) = \\lVert \\mathbf{X} \\mathbf{w} - \\mathbf{y} \\rVert_2^2 + \\lambda \\lVert \\mathbf{w} \\rVert_2\n",
        "$$\n",
        "\n",
        "and with solution\n",
        "\n",
        "$$\n",
        "\\mathbf{w}_{\\text{MAP}} = (\\mathbf{X}^\\top \\mathbf{X} + \\lambda I)^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
        "$$\n",
        "\n",
        "where $I$ is the identity matrix. We can get the OLS solution by setting `λ=0.0`, so we re-use the code for Ridge to get the OLS solution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Io7UKX1mhvgu"
      },
      "outputs": [],
      "source": [
        "class Ridge:\n",
        "    def __init__(self, λ: float):\n",
        "        self.λ = λ\n",
        "\n",
        "    def copy(self):\n",
        "        return Ridge(self.λ)\n",
        "\n",
        "# Convenience constructor for OLS (λ=0.0)\n",
        "def OLS():\n",
        "    return Ridge(0.0)\n",
        "\n",
        "def train_ridge(ridge: Ridge, model, X, Y):\n",
        "    λ = ridge.λ\n",
        "    n = X.shape[1]\n",
        "    model.W = np.linalg.inv(X.T @ X + λ * np.eye(n)) @ X.T @ Y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7SRxRpUlCSh"
      },
      "source": [
        "## Lasso regression\n",
        "Lasso regression corresponds to the $\\ell_1$ regularized problem with the cost function:\n",
        "\n",
        "$$\n",
        "c(\\mathbf{w}) = \\lVert \\mathbf{X} \\mathbf{w} - \\mathbf{y} \\rVert_2^2 + \\lambda \\lVert \\mathbf{w} \\rVert_1\n",
        "$$\n",
        "\n",
        "Unlike $\\ell_2$ regularization, there is no closed-form solution. So, we have to solve iteratively. Further, this objective is non-differentiable when $ \\mathbf{w} = \\mathbf{0}$, making gradient descent perform poorly. Instead, we use proximal gradient descent, to get the Lasso regressor. See your notes for the algorithm. You will need to fill in two functions for this portion:\n",
        "- `prox_l1` : the proximal operator taking a weight, a step size, and the regularization parameter\n",
        "- `train` : which performs Lasso regression using `prox_l1`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-pLp9NFxmZvi"
      },
      "outputs": [],
      "source": [
        "class Lasso:\n",
        "    def __init__(self, λ: float, τ: float):\n",
        "        self.λ = λ\n",
        "        self.τ = τ  # Tolerance\n",
        "\n",
        "    def copy(self):\n",
        "        return Lasso(self.λ, self.τ)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vH-I1OfnnE9g"
      },
      "outputs": [],
      "source": [
        "def prox_l1(w, η, λ):\n",
        "  #BEGIN SOLUTION\n",
        "  if w > η * λ:\n",
        "    return w - (η * λ)\n",
        "  elif w < -η * λ:\n",
        "    return w + (η * λ)\n",
        "  else:\n",
        "    return 0\n",
        "  #END SOLUTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bGIEdskxnUpb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# ##############\n",
        "# Test Block\n",
        "# ##############\n",
        "\n",
        "assert prox_l1(0.1, 1.0, 0.15) == 0.0, \"First test Failed! ❌\"\n",
        "assert prox_l1(1.0, 0.1, 0.15) == 0.985, \"Second test Failed! ❌\"\n",
        "assert prox_l1(-1.3, 0.03, 0.2) == -1.294, \"Third test Failed! ❌\"\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Tests passed! ✅\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FxveuP9RnmKL"
      },
      "outputs": [],
      "source": [
        "def train_lasso(lasso, model, X, Y):\n",
        "    n = X.shape[0]  # number of samples\n",
        "    λ = lasso.λ\n",
        "    τ = lasso.τ  # tolerance\n",
        "    err = float('inf')  # Initialize error as infinity\n",
        "    η = 1/(2*np.linalg.norm((1 / n) * np.dot(X.T, X))) # Learning rate\n",
        "    Y = np.atleast_2d(Y).T\n",
        "\n",
        "    def c(x):\n",
        "        # Calculate the cost function\n",
        "        e = model.predict(x) - Y\n",
        "        return np.dot(e.T,e) + λ * np.sum(np.abs(model.W))  # L1 regularization term\n",
        "\n",
        "    #### BEGIN SOLUTION\n",
        "\n",
        "    # Covariance matrix of input data X\n",
        "    XX = (1/n) * (X.T @ X)\n",
        "    # Calculate XY\n",
        "    XY = (1/n) * (X.T @ Y)\n",
        "    while np.abs(c(X) - err) > τ:\n",
        "        # Update the error with the current loss value\n",
        "        err = c(X)\n",
        "        # Compute the gradient and update the weights (ΔW is the weight update)\n",
        "        g = XX @ model.W - XY\n",
        "        # Apply the soft thresholding function to each weight in the model\n",
        "        w = model.W - η*g\n",
        "        for i, _ in enumerate(w):\n",
        "            w[i] = prox_l1(w[i], η, λ)\n",
        "        # Apply L1 regularization to all weights\n",
        "        model.W = w\n",
        "\n",
        "    #### END SOLUTION\n",
        "Lasso.train = train_lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0FoUnf-eoket"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed MSE: 0.04946101964285601\n",
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# ##############\n",
        "# Test Block\n",
        "# ##############\n",
        "np.random.seed(2)\n",
        "\n",
        "# Creating Lasso object with λ = 0.1, τ = 0.01\n",
        "ols = Lasso(0.1, 0.01)\n",
        "\n",
        "# Generating data\n",
        "X = np.random.rand(1000, 6)\n",
        "W = np.random.rand(6, 1)\n",
        "Y = np.dot(X, W) + np.random.randn(1000, 1) * 0.1  # Adding noise\n",
        "Y = Y.flatten()\n",
        "\n",
        "# Linear model\n",
        "m = LinearModel(6, 1)\n",
        "\n",
        "# Train the model using Lasso regularization\n",
        "Lasso.train(ols, m, X, Y)\n",
        "\n",
        "# Testing mean squared error (MSE)\n",
        "mse = np.mean((np.dot(X, m.W) - np.atleast_2d(Y).T) ** 2)\n",
        "\n",
        "print(f\"Computed MSE: {mse}\")  # Debug: Print the computed MSE\n",
        "\n",
        "# Assert the computed MSE is close to the expected value\n",
        "assert np.isclose(mse, 0.049461019642855916, atol=1e-6), \"Check your train_lasso function! ❌\"  # Compare with the expected value\n",
        "\n",
        "\n",
        "print(f\"Tests passed! ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE9d39uqjwNd"
      },
      "source": [
        "# Moving to the KernelModel and Prototype Representations\n",
        "\n",
        "The `KernelModel` does nonlinear regression by first transforming the features using a kernel representation (which we also call a prototype representation) and then calling our standard linear regression algorithms. But, for these models, instead of using the closed-form solution above, we will move to gradient descent. We do so because the dimension of our features can be much higher, and so the closed-form solution is more expensive that doing gradient descent. Note also that with more features it is more likely for $\\mathbf{X}^\\top \\mathbf{X}$ to be ill-conditioned or not invertible, and stochastic gradient descent provides some robustness to this ill-conditioning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NH_tqtH9k9bf"
      },
      "outputs": [],
      "source": [
        "def train(ls, model, X, Y):\n",
        "\t# build K matrix\n",
        "\tK = get_features(model, X)\n",
        "\ttrain(ls, model.model, K, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5dsOAZqlPLe"
      },
      "source": [
        "## Gradient Descent\n",
        "In this notebook, we will focus on minibatch gradient descent wiht a constant learning rate, implemented in `ConstantLR`. We also provide `RMSProp` for you, primarily to run as a comparison and for your interest.\n",
        "\n",
        "Below, you need to implement the function `epoch` which goes through the dataset in minibatches of size `mbgd.n`. Remember to randomize how you go through the data **and** ensure you are using the correct targets for the data passed to the learning update. In this implementation, you will use:\n",
        "\n",
        "```python\n",
        "update(model, lossfunc, opt, X_batch, Y_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fdR4tOv_uNzk"
      },
      "outputs": [],
      "source": [
        "class MiniBatchGD:\n",
        "    def __init__(self, n: int):\n",
        "        self.n = n\n",
        "\n",
        "class AbstractModel(ABC):\n",
        "    @abstractmethod\n",
        "    def predict(self, X):\n",
        "        pass\n",
        "class Optimizer(ABC): #added by me\n",
        "    @abstractmethod\n",
        "    def copy(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6xuEsNrdultU"
      },
      "outputs": [],
      "source": [
        "def epoch(mbgd, model, lossfunc, opt, X, Y):\n",
        "    \"\"\"\n",
        "    Perform one epoch of mini-batch gradient descent.\n",
        "\n",
        "    Args:\n",
        "        mbgd (MiniBatchGD): The MiniBatchGD object containing batch size.\n",
        "        model (AbstractModel): The model to update.\n",
        "        lossfunc (function): The loss function to compute the gradient.\n",
        "        opt (Optimizer): The optimizer to use for the update.\n",
        "        X (numpy.ndarray): Input features.\n",
        "        Y (numpy.ndarray): Target values.\n",
        "    \"\"\"\n",
        "\n",
        "    rand_idx = np.random.RandomState(seed=42).permutation(Y.shape[0])  # Randomize the indices\n",
        "\n",
        "   \t#### BEGIN SOLUTION\n",
        "\n",
        "    # Calculate number of batches\n",
        "    num_batches = mbgd.n\n",
        "\n",
        "    for i in range(num_batches):\n",
        "\n",
        "        # Determine the batch indices\n",
        "        batch = np.array_split(rand_idx, num_batches)[i]\n",
        "        X_batch = X[batch]\n",
        "        Y_batch = Y[batch]\n",
        "        # Update the model using the current batch\n",
        "        opt.update(model, lossfunc, opt, X_batch, Y_batch)\n",
        "\n",
        "\n",
        "    #### END SOLUTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jRO0vSsyqdte"
      },
      "outputs": [],
      "source": [
        "def train(mbgd, model, lossfunc, opt, X, Y, num_epochs):\n",
        "    if isinstance(model, AbstractModel):\n",
        "        model = model.get_linear_model()\n",
        "        X = model.get_features(X)\n",
        "\n",
        "    # Initialize loss array\n",
        "    L = np.zeros(num_epochs + 1)\n",
        "\n",
        "    L[0] = calculate_loss(model, lossfunc, X, Y)\n",
        "\n",
        "    # Training loop\n",
        "    for i in range(num_epochs):\n",
        "        epoch(mbgd, model, lossfunc, opt, X, Y)\n",
        "        L[i + 1] = calculate_loss(model, lossfunc, X, Y)\n",
        "\n",
        "    return L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2-U8kyZywJHP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# ################\n",
        "# Test Block\n",
        "# ################\n",
        "class LR():\n",
        "    pass\n",
        "\n",
        "class LF():\n",
        "    pass\n",
        "\n",
        "def gradient(lm, lf, X, Y):\n",
        "    return X.sum(axis=0)\n",
        "\n",
        "def update(self, lm, lf, opt, X, Y):\n",
        "    ΔW = gradient(lm, lf, X, Y)\n",
        "    lm.W -= ΔW.reshape(-1,1)\n",
        "LR.update = update\n",
        "\n",
        "lm = LinearModel(3, 1)\n",
        "opt = LR()\n",
        "lf = LF()\n",
        "X = np.ones((10, 3))\n",
        "Y = np.arange(0.0, 1.0, 0.1)\n",
        "mbgd = MiniBatchGD(5)\n",
        "epoch(mbgd, lm, lf, opt, X, Y)\n",
        "\n",
        "assert np.all(lm.W == -10.0),  \"Test Failed! ❌\"\n",
        "\n",
        "print(f\"Tests passed! ✅\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UdX_7StkyIsa"
      },
      "outputs": [],
      "source": [
        "class TestModel:\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = np.zeros_like(X)\n",
        "        self.Y = np.zeros_like(Y)\n",
        "        self.position = 1\n",
        "        self.W = np.zeros((X.shape[1], 1))  # Initialize weights (W) as zeros, assuming linear model\n",
        "\n",
        "\n",
        "    def update(self, X, Y):\n",
        "        end_idx_X = self.position + X.shape[0] - 1\n",
        "        end_idx_Y = self.position + Y.shape[0] - 1\n",
        "\n",
        "        self.X[self.position:end_idx_X + 1, :] = X\n",
        "        self.Y[self.position:end_idx_Y + 1, :] = Y\n",
        "        self.position += X.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "X7ibLAMcyP4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# Initialize objects for the test\n",
        "__epoch_opt = LR()   # Optimizer\n",
        "__epoch_lf = LF()    # Loss function\n",
        "\n",
        "# Random data generation for X and Y\n",
        "__epoch_X = np.random.RandomState(seed=42).rand(10, 3)\n",
        "__epoch_Y = np.random.RandomState(seed=42).rand(10)\n",
        "\n",
        "# Create the model instance\n",
        "__epoch_model = TestModel(__epoch_X, __epoch_Y)\n",
        "\n",
        "# Create MiniBatchGD instance\n",
        "__epoch_mbgd = MiniBatchGD(5)\n",
        "\n",
        "# Call the epoch function (this is the core logic to test)\n",
        "epoch(__epoch_mbgd, __epoch_model, __epoch_lf, __epoch_opt, __epoch_X, __epoch_Y)\n",
        "\n",
        "# Check if the model data has been updated (asserting that model X and Y are not equal to input X and Y)\n",
        "test_passed = not (np.array_equal(__epoch_model.X, __epoch_X) or np.array_equal(__epoch_model.Y, __epoch_Y))\n",
        "assert test_passed,  \"Test Failed! ❌\"\n",
        "\n",
        "print(f\"Tests passed! ✅\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo-07sJ74veP"
      },
      "source": [
        "## Loss Functions\n",
        "For this notebook, we will only be using MSE, but we still introduce the abstract type `LossFunction` for future use. Below, you will need to implement the `loss`  function and the `gradient` function for MSE.\n",
        "\n",
        "Please use this scaled MSE for the loss and gradient:\n",
        "\n",
        "$$\n",
        "\\text{MSE}(\\hat{\\mathbf{y}}, \\mathbf{y}) = \\frac{1}{2n} \\sum_{i=1}^n (\\hat{y_i} - y_i)^2\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6r_isghd6bnp"
      },
      "outputs": [],
      "source": [
        "class LossFunction(ABC):\n",
        "    pass\n",
        "\n",
        "class MSE(LossFunction):\n",
        "    \"\"\"\n",
        "    MSE computes the mean squared error loss.\n",
        "    \"\"\"\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zSJtt7Y36rtq"
      },
      "outputs": [],
      "source": [
        "def loss(self, y_hat, y):\n",
        "    \"\"\"\n",
        "    Compute the mean squared error loss between target `y` and prediction `y_hat`\n",
        "    \"\"\"\n",
        "    #### BEGIN SOLUTION\n",
        "    # Compute the error between predictions and actual values\n",
        "\n",
        "    mse = np.mean(np.square(y_hat - y))\n",
        "\n",
        "    # Return the mean squared error (scaled by 1 / (2))\n",
        "\n",
        "    return mse/2\n",
        "    #### END SOLUTION\n",
        "\n",
        "MSE.loss = loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zHhnHf-467Tm"
      },
      "outputs": [],
      "source": [
        "def calculate_loss(self, lf, X, Y):\n",
        "    \"\"\"\n",
        "    Compute the loss between the target `Y` and the prediction of `lm` on input data `X`\n",
        "    \"\"\"\n",
        "    Y_hat = 0  # Initialize the predicted values to 0\n",
        "\n",
        "\n",
        "    Y_hat = self.predict(X)  # Compute the predictions using the model\n",
        "\n",
        "    # Calculate and return the loss using the provided loss function\n",
        "    return lf.loss(Y_hat, Y)\n",
        "\n",
        "LinearModel.calculate_loss = calculate_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "kZmADoVAGQx2"
      },
      "outputs": [],
      "source": [
        "def gradient(self, mse, X, Y):\n",
        "    \"\"\"\n",
        "    Compute the gradient of the loss function with respect to the model weights.\n",
        "    \"\"\"\n",
        "    deltaW = np.zeros_like(self.W)  # gradients should be the size of the weights\n",
        "\n",
        "    #### BEGIN SOLUTION\n",
        "\n",
        "\n",
        "    # Calculate the error (predictions - actual values)\n",
        "    prediction = self.predict(X) - Y.reshape(-1,1)\n",
        "    # Compute the gradient\n",
        "    deltaW = (X.T @ prediction) / len(Y)\n",
        "    #### END SOLUTION\n",
        "\n",
        "\n",
        "    # Ensure that the gradient shape matches the weights shape\n",
        "    assert deltaW.shape == self.W.shape\n",
        "    return deltaW\n",
        "\n",
        "LinearModel.gradient = gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "0MUbWSFaLrca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed MSE loss: 3.75\n",
            "Computed gradient: [[-2.5]\n",
            " [-2.5]\n",
            " [-2.5]]\n",
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# ############\n",
        "# Test Block\n",
        "# ############\n",
        "\n",
        "\n",
        "result_mseloss = LinearModel(3, 1).calculate_loss(MSE(), np.ones((4, 3)), np.array([1, 2, 3, 4]))\n",
        "print(f\"Computed MSE loss: {result_mseloss}\")\n",
        "assert result_mseloss == 3.75, \"Error in MSE loss calculation. ❌\"\n",
        "\n",
        "\n",
        "gradient_result = LinearModel(3, 1).gradient( MSE(), np.ones((4, 3)), np.array([1, 2, 3, 4]))\n",
        "print(f\"Computed gradient: {gradient_result}\")\n",
        "__check_msegrad = np.all(gradient_result == -2.5)\n",
        "assert  __check_msegrad, \"Error in MSE gradient calculation. ❌\"\n",
        "\n",
        "print(f\"Tests passed! ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80toZhz3Wv43"
      },
      "source": [
        "## Optimizers\n",
        "Below you will need to implement  optimizer:\n",
        "\n",
        "- Constant learning rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9uLMfS6DmRS"
      },
      "source": [
        "#### Constant Learning Rate\n",
        "\n",
        "`ConstantLR` updates the weights using a constant learning rate $η$\n",
        "\n",
        "$$\n",
        "\\mathbf{w} = \\mathbf{w} - η \\cdot \\mathbf{g}\n",
        "$$\n",
        "\n",
        "where $g$ is the gradient defined by the loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "HBAFk7cMD3jc"
      },
      "outputs": [],
      "source": [
        "class ConstantLR:\n",
        "    \"\"\"\n",
        "    ConstantLR represents an optimizer with a constant learning rate.\n",
        "    \"\"\"\n",
        "    def __init__(self, eta):\n",
        "        self.eta = float(eta)\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"\n",
        "        Create a copy of the ConstantLR instance.\n",
        "        \"\"\"\n",
        "        return ConstantLR(self.eta)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ohSIo7ghECI3"
      },
      "outputs": [],
      "source": [
        "def update(self, lm, lf, opt, x, y):\n",
        "    \"\"\"\n",
        "    Update the weights of the LinearModel using the provided loss function, optimizer,\n",
        "    input data, and target values.\n",
        "\n",
        "    Parameters:\n",
        "        lm: LinearModel\n",
        "            The linear model to be updated.\n",
        "        lf: LossFunction\n",
        "            The loss function to compute gradients.\n",
        "        opt: ConstantLR\n",
        "            The optimizer with a constant learning rate.\n",
        "        x: numpy.ndarray\n",
        "            The input data matrix.\n",
        "        y: numpy.ndarray\n",
        "            The target values vector.\n",
        "    \"\"\"\n",
        "    # Compute the gradient\n",
        "    g = gradient(lm, lf, x, y)\n",
        "\n",
        "    #### BEGIN SOLUTION\n",
        "    # Update weights\n",
        "    lm.W -= opt.eta * g\n",
        "\n",
        "    #### END SOLUTION\n",
        "ConstantLR.update = update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "4qLIy472Fyua"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# ##############\n",
        "# Test Block\n",
        "# ##############\n",
        "\n",
        "lm = LinearModel(3, 1)  # Create a LinearModel with 3 features and 1 output\n",
        "opt = ConstantLR(0.1)   # Optimizer with a learning rate of 0.1\n",
        "lf = MSE()              # Mean Squared Error loss function\n",
        "X = np.ones((4, 3))     # Input data: 4 samples with 3 features each\n",
        "Y = np.array([0.1, 0.2, 0.3, 0.4])  # Target values\n",
        "opt.update(lm, lf, opt, X, Y)  # Perform a single update step\n",
        "assert np.all(lm.W == 0.025), \"Failed ConstantLR test. ❌\"\n",
        "\n",
        "\n",
        "print(f\"Tests passed! ✅\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvQp10SyGZ3n"
      },
      "source": [
        "#### RMSProp\n",
        "\n",
        "RMSProp is a first-order adaptive stepsize optimizer proposed by Geoff Hinton [in this lecture](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf), similar to ADAM but without Momentum. We provide this optimizer for you, as it is only here as a comparator for your interest. The update equations are as follows:\n",
        "\n",
        "$\n",
        "v_i = \\rho \\cdot v_i + (1 - \\rho) \\cdot g_i^2\n",
        "$\n",
        "\n",
        "$\n",
        "W_i = W_i - \\frac{\\eta}{\\sqrt{v_i + \\epsilon}} \\cdot g_i\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "1R82bagPGwFv"
      },
      "outputs": [],
      "source": [
        "class RMSProp:\n",
        "    \"\"\"\n",
        "    RMSProp optimizer class.\n",
        "\n",
        "    Attributes:\n",
        "    - eta (float): Step size\n",
        "    - rho (float): Decay parameter\n",
        "    - v (np.ndarray): Exponentially decaying average\n",
        "    - epsilon (float): Small constant to prevent division by zero\n",
        "    \"\"\"\n",
        "    def __init__(self, eta, rho, v=None, epsilon=1e-5):\n",
        "        self.eta = eta  # Step size\n",
        "        self.rho = rho  # Decay parameter\n",
        "        self.v = v if v is not None else np.zeros((1, 1))  # Default v is a 1x1 zero matrix\n",
        "        self.epsilon = epsilon  # Small constant for numerical stability\n",
        "\n",
        "    @classmethod\n",
        "    def from_linear_model(cls, eta, rho, lm):\n",
        "        \"\"\"\n",
        "        Alternative constructor for initializing RMSProp with a LinearModel.\n",
        "        \"\"\"\n",
        "        return cls(eta, rho, np.zeros_like(lm.W), 1e-5)\n",
        "\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"\n",
        "        Create a copy of the RMSProp instance, resetting the exponential average to zeros.\n",
        "        \"\"\"\n",
        "        return RMSProp(self.eta, self.rho, np.zeros_like(self.v), self.epsilon)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "y-z8tQwrHBp5"
      },
      "outputs": [],
      "source": [
        "def update_rmsprop(self, lm, lf, opt, x, y):\n",
        "    \"\"\"\n",
        "    Update the weights of a LinearModel using the RMSProp optimizer.\n",
        "\n",
        "    Parameters:\n",
        "    - lm: LinearModel instance.\n",
        "    - lf: LossFunction instance.\n",
        "    - opt: RMSProp optimizer instance.\n",
        "    - x: Input matrix (features).\n",
        "    - y: Target vector.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute gradient\n",
        "    g = gradient(lm, lf, x, y)\n",
        "\n",
        "    # Ensure `v` is of the correct shape\n",
        "    if g.shape != opt.v.shape:\n",
        "        opt.v = np.zeros_like(g)\n",
        "\n",
        "    # Unpack optimizer parameters\n",
        "    eta, rho, v, epsilon = opt.eta, opt.rho, opt.v, opt.epsilon\n",
        "\n",
        "    # Update `v` and `lm.W`\n",
        "    # Element-wise update for `v`\n",
        "    v[:] = rho * v + (1 - rho) * np.square(g)\n",
        "    # Update weights with RMSProp rule\n",
        "    lm.W[:] -= eta * (g / np.sqrt(v + epsilon))\n",
        "\n",
        "RMSProp.update = update_rmsprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "fuO9sousHLk6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tests passed! ✅\n"
          ]
        }
      ],
      "source": [
        "# #################\n",
        "# Test Block:\n",
        "# #################\n",
        "\n",
        "# Create a LinearModel, RMSProp optimizer, and sample data\n",
        "lm = LinearModel(2, 1)\n",
        "opt = RMSProp.from_linear_model(0.1, 0.9, lm)\n",
        "X = np.array([[0.1, 0.5],\n",
        "              [0.5, 0.0],\n",
        "              [1.0, 0.2]])\n",
        "Y = np.array([1, 2, 3])\n",
        "\n",
        "# Perform the update\n",
        "opt.update(lm, MSE(), opt, X, Y)\n",
        "\n",
        "\n",
        "# Define expected values for `v` and `W`\n",
        "true_v = np.array([[0.18677777777777768], [0.013444444444444445]])\n",
        "\n",
        "true_W = np.array([[0.31621930100905377], [0.3161102262149725]])\n",
        "\n",
        "# Check if the computed values match the expected ones\n",
        "assert np.allclose(opt.v, true_v, atol=1e-3), \"Wrong values for v. ❌\"\n",
        "assert np.allclose(lm.W, true_W, atol=1e-4), \"Wrong values for W. ❌\"\n",
        "\n",
        "\n",
        "print(f\"Tests passed! ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKzO5jsDeG4I"
      },
      "source": [
        "# Prototype Selection for Kernels\n",
        "\n",
        "Now that we have some learning methods defined, we can explore prototype selection strategies for our kernel models. Prototype selection involves picking samples $\\mathbf{x}_i$ from our dataset as representative or prototypical points.\n",
        "\n",
        "1. **Random Prototype Selection**: A random subset of prototypes are selected. This naive baseline is often hard to beat.\n",
        "2. **Lasso-Based Prototype Selection**: Leverages the sparsity induced by Lasso regression to identify prototypes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "46JsWh5_eSLG"
      },
      "outputs": [],
      "source": [
        "class PrototypeSelectionStrategy(ABC):\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns13AAw9eV4a"
      },
      "source": [
        "### Random Prototypes from Data\n",
        "\n",
        "This algorithm selects a random set of `p` prototypes from the data. Surprisingly, this approach is quite effe`tive, as demonstrated in the experiments below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "lstosxiOelxS"
      },
      "outputs": [],
      "source": [
        "class RandomPrototypes:\n",
        "    \"\"\"\n",
        "    A prototype selection strategy that selects a random set of p prototypes from the data.\n",
        "    \"\"\"\n",
        "    def __init__(self, p):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            p (int): Number of prototypes to select.\n",
        "        \"\"\"\n",
        "        self.p = p\n",
        "\n",
        "    def select_prototypes(self, kern_func, X, Y):\n",
        "        \"\"\"\n",
        "        Selects random prototypes from the data.\n",
        "\n",
        "        Parameters:\n",
        "            kern_func: Kernel function (not used in this implementation).\n",
        "            X: Data matrix.\n",
        "            Y: Labels vector (not used in this implementation).\n",
        "\n",
        "        Returns:\n",
        "            List of selected prototypes.\n",
        "        \"\"\"\n",
        "        # Randomly select 'p' prototypes from X\n",
        "        prototype_idx = np.random.choice(X.shape[0], self.p, replace=False)\n",
        "        return [X[i, :] for i in prototype_idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qvjcWqDfRP8"
      },
      "source": [
        "### L1 Strategy for selecting prototypes\n",
        "\n",
        "In this section we will make a novel center selection algorithm based on using L1 regularization. You will need to implement `select_prototypes` which returns an array of prototypes (see `RandomPrototypes` for an example). These prototypes will be selected based on our implementation of `Lasso`. You will use `Lasso` with parameters `L1Prototypes.λ` and `L1Prototypes.τ`, and do a regression on a random set of prototypes `start_p`. Once you do this regression you will use `maxk_idx` to return the top `p` prototypes based off the absolute values of the model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "kLvx5BLgfiJb"
      },
      "outputs": [],
      "source": [
        "class L1Prototypes:\n",
        "    \"\"\"\n",
        "    A prototype selection strategy that uses L1 regularization to select prototypes.\n",
        "    \"\"\"\n",
        "    def __init__(self, λ, τ, p, start_p):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            λ (float): Regularization parameter for Lasso regression.\n",
        "            τ (float): Decay factor.\n",
        "            p (int): Number of prototypes to select.\n",
        "            start_p (int): Starting number of prototypes.\n",
        "        \"\"\"\n",
        "        self.λ = λ\n",
        "        self.τ = τ\n",
        "        self.p = p\n",
        "        self.start_p = start_p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "LYI0g07LgduG"
      },
      "outputs": [],
      "source": [
        "def select_prototypes(self, kern_func, X, Y):\n",
        "\n",
        "    #### BEGIN SOLUTION\n",
        "\n",
        "    # Randomly select initial prototypes\n",
        "    prototype_idx = np.random.choice(X.shape[0], self.p, replace=False)\n",
        "    cur_prototypes = X[prototype_idx, :]\n",
        "\n",
        "    # Create the KernelModel\n",
        "    km = KernelModel(kern_func, prototype_idx)\n",
        "    # Use previously defined Lasso model\n",
        "    lasso = Lasso(0.1, 0.1)\n",
        "    # Train the Lasso model\n",
        "    train_lasso(lasso, km, X, Y)\n",
        "    # Get the indices of the n largest coefficients (Lasso weights)\n",
        "\n",
        "    # Return the selected prototypes based on the sorted indices\n",
        "\n",
        "    #### END SOLUTION\n",
        "\n",
        "    return X[sorted_idx]\n",
        "\n",
        "L1Prototypes.select_prototypes = select_prototypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "NZy1r9dAiUs2"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "object of type 'numpy.int64' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[83], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Select prototypes using L1Prototypes first\u001b[39;00m\n\u001b[1;32m     22\u001b[0m prototype_selection_strategy \u001b[38;5;241m=\u001b[39m L1Prototypes(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m selected_prototypes \u001b[38;5;241m=\u001b[39m \u001b[43mprototype_selection_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_prototypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkern_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Now, pass the selected prototypes to the KernelModel\u001b[39;00m\n\u001b[1;32m     26\u001b[0m km \u001b[38;5;241m=\u001b[39m KernelModel(kern_func, prototypes\u001b[38;5;241m=\u001b[39mselected_prototypes, prototype_selection_strategy\u001b[38;5;241m=\u001b[39mprototype_selection_strategy)\n",
            "Cell \u001b[0;32mIn[82], line 10\u001b[0m, in \u001b[0;36mselect_prototypes\u001b[0;34m(self, kern_func, X, Y)\u001b[0m\n\u001b[1;32m      7\u001b[0m cur_prototypes \u001b[38;5;241m=\u001b[39m X[prototype_idx, :]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create the KernelModel\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m km \u001b[38;5;241m=\u001b[39m \u001b[43mKernelModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkern_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprototype_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Use previously defined Lasso model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m lasso \u001b[38;5;241m=\u001b[39m Lasso(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n",
            "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mKernelModel.__init__\u001b[0;34m(self, kern, prototypes, out, prototype_selection_strategy)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototype_selection_strategy \u001b[38;5;241m=\u001b[39m prototype_selection_strategy\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprototypes \u001b[38;5;241m=\u001b[39m prototypes\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m LinearModel(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprototypes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, out)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# If no prototypes, initialize a blank kernel model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkern \u001b[38;5;241m=\u001b[39m kern\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
          ]
        }
      ],
      "source": [
        "# #############\n",
        "# Test Block\n",
        "# #############\n",
        "\n",
        "# Setting random seed for reproducibility\n",
        "np.random.seed(2)\n",
        "\n",
        "# Kernel model with RBF kernel and L1Prototypes\n",
        "kern_func = RBF(0.9)\n",
        "# Generate random input data\n",
        "rng = np.random.default_rng(2)\n",
        "X = rng.random((10, 4))  # Example: generates a 10x4 random array\n",
        "\n",
        "# Define the target function\n",
        "def m(x):\n",
        "    return np.sin(np.pi * x[0]) + np.sin(np.pi * x[1]) + np.sin(np.pi * (x[2] + x[3]) / 2)\n",
        "\n",
        "# Generate target labels\n",
        "Y = np.array([[m(x) for x in X]])\n",
        "\n",
        "# Select prototypes using L1Prototypes first\n",
        "prototype_selection_strategy = L1Prototypes(0.1, 0.001, 4, 10)\n",
        "selected_prototypes = prototype_selection_strategy.select_prototypes(kern_func, X, Y)\n",
        "\n",
        "# Now, pass the selected prototypes to the KernelModel\n",
        "km = KernelModel(kern_func, prototypes=selected_prototypes, prototype_selection_strategy=prototype_selection_strategy)\n",
        "\n",
        "\n",
        "# Update the model with the new data and check the number of prototypes\n",
        "update_transform(km, X, Y.T)\n",
        "\n",
        "assert len(km.prototypes) == 4, \"Wrong values for W. ❌\"\n",
        "\n",
        "print(f\"Tests passed! ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1FwtBESnbWq"
      },
      "source": [
        "# Evaluating models\n",
        "\n",
        "In the following section, we provide a few helper functions and structs to make evaluating methods straightforward. The abstract type `LearningProblem` with children `GDLearningProblem` is used to construct a learning problem. You will notice these structs contain all the information needed to `train` a model for both gradient descent and for OLS. We also provide the `run_GD` function. These will update the transform according to the provided data and train the model. `run_GD` does this with a copy of the learning problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_f5q_hsnzDc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "class LearningProblem(ABC):\n",
        "    \"\"\"\n",
        "    Abstract base class for defining a learning problem.\n",
        "    \"\"\"\n",
        "    @abstractmethod\n",
        "    def train(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llNTb-LOrxnh"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Define placeholder types for the model, optimizer, and loss function\n",
        "M = TypeVar('M', bound='AbstractModel')\n",
        "O = TypeVar('O', bound='Optimizer')\n",
        "LF = TypeVar('LF', bound='LossFunction')\n",
        "\n",
        "class GDLearningProblem:\n",
        "    \"\"\"\n",
        "    This is a class for keeping the necessary gradient descent learning setting components together.\n",
        "    \"\"\"\n",
        "    def __init__(self, gd, model, opt, loss):\n",
        "        self.gd = gd\n",
        "        self.model = model\n",
        "        self.opt = opt\n",
        "        self.loss = loss\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"\n",
        "        Create a copy of the GDLearningProblem instance.\n",
        "\n",
        "        Returns:\n",
        "            GDLearningProblem: A new instance with copied components.\n",
        "        \"\"\"\n",
        "        return GDLearningProblem(\n",
        "            self.gd,\n",
        "            self.model.copy(),\n",
        "            self.opt.copy(),\n",
        "            self.loss\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkxipplIyhTd"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def run_GD(lp, X, Y, num_epochs):\n",
        "    # Update the model transformation with the provided data\n",
        "    update_transform(lp.model, X, Y)\n",
        "\n",
        "    # Train the model using the gradient descent optimizer\n",
        "    loss = train(lp.gd, lp.model, lp.loss, lp.opt, X, Y, num_epochs)\n",
        "\n",
        "    return lp, loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKhY72_QH-Ae"
      },
      "source": [
        "In this section you will implement two functions to implement cross validation with random repeated subsampling.`random_dataset_split`: randomly splits the data `X` and `Y` into a training set and a validation set. This will also be used to split out data into a training set and test set. This function returns two tuples `(X_train, Y_train), (X_test, Y_test)`. `cross_validation` $(_check_complete(__check_cross_validation)): This does `k` independent experiments of the given LearningProblem. The function trains the model and then stores the error according to the **Root Mean Squared Error** (no matter what the loss is in the learning problem), storing this in `cv_err`. `cv_err` is then returned. Because these functions require randomness, the check marks which have been used to check correctness before only check for returning the correct datatypes (for `random_dataset_split`) or that the returned vector of numbers `cv_err` is non-zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eh7Xll_CyJT"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def random_dataset_split(X, Y, n_train):\n",
        "    # Randomly shuffle the indices\n",
        "    indices = np.random.permutation(len(Y))\n",
        "\n",
        "    # BEGIN SOLUTION\n",
        "\n",
        "    # Split the indices into training and testing sets\n",
        "\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "\n",
        "\n",
        "    # Return two tuples: (X_train, Y_train), (X_test, Y_test)\n",
        "    return\n",
        "    # END SOLUTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZX1mqypIN2a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# #############\n",
        "# Test Block\n",
        "# #############\n",
        "# Set the random seed\n",
        "rng = np.random.default_rng(10)\n",
        "\n",
        "# Generate random X and Y\n",
        "X = rng.random((10, 3))\n",
        "Y = rng.random(10)\n",
        "\n",
        "# Call the random dataset split function\n",
        "data = random_dataset_split(X, Y, 8)\n",
        "\n",
        "assert data is not None, \"Data is None. ❌\"\n",
        "\n",
        "d_train = data[0]\n",
        "d_test = data[1]\n",
        "\n",
        "# Check dimensions of training and test sets\n",
        "assert    d_train[0].shape == (8, 3), \"Wrong shape for X train. ❌\"\n",
        "assert    d_train[1].shape == (8,),   \"Wrong shape for Y train. ❌\"\n",
        "assert    d_test[0].shape == (2, 3), \"Wrong shape for X test. ❌\"\n",
        "assert    d_test[1].shape == (2,), \"Wrong shape for Y test. ❌\"\n",
        "\n",
        "print(f\"Tests passed! ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foR7txUUI8Dl"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def cross_validation(lp, X, Y, num_epochs, k, train_size=None):\n",
        "    \"\"\"\n",
        "    Perform k-fold cross-validation for a given LearningProblem.\n",
        "\n",
        "    Parameters:\n",
        "        lp: LearningProblem object.\n",
        "        X: np.ndarray - Input data.\n",
        "        Y: np.ndarray - Target labels.\n",
        "        num_epochs: int - Number of epochs for training.\n",
        "        k: int - Number of folds.\n",
        "        train_size: int (optional) - Size of the training set (default 90% of data).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray - Cross-validation errors (MSE for each fold).\n",
        "    \"\"\"\n",
        "    if train_size is None:\n",
        "        train_size = int(floor(X.shape[0] * 0.9))\n",
        "\n",
        "    cv_err = np.zeros(k)\n",
        "\n",
        "    for i in range(k):\n",
        "        # BEGIN SOLUTION\n",
        "        # Split data into training and validation sets\n",
        "\n",
        "        # Train the model (use run_GD function)\n",
        "\n",
        "\n",
        "        # Predict on validation data\n",
        "\n",
        "        # Compute MSE and store in cv_err\n",
        "        cv_err[i] =\n",
        "\n",
        "        # END SOLUTION\n",
        "\n",
        "    return cv_err\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH-Eh7VJJS2V"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#############\n",
        "# Test Block\n",
        "# #############\n",
        "\n",
        "np.random.seed(2)\n",
        "num_epochs = 100\n",
        "\n",
        "# Generate random data\n",
        "X = np.random.rand(5000, 10)\n",
        "X[:, 1] = 0.1 * X[:, 2]\n",
        "X[:, 4] = 0.5 * (X[:, 5] + X[:, 6])\n",
        "\n",
        "# Generate weights and target Y\n",
        "w = np.random.rand(10)\n",
        "Y = (X @ w) + np.random.randn(5000) * 0.001\n",
        "\n",
        "# Set up the learning problem\n",
        "lp = GDLearningProblem(\n",
        "    MiniBatchGD(30),          # Mini-batch gradient descent with batch size 30\n",
        "    LinearModel(X.shape[1], 1),          # Linear model with input size equal to X's columns\n",
        "    ConstantLR(0.01),                    # Constant learning rate of 0.01\n",
        "    MSE()                                # Mean Squared Error loss function\n",
        ")\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_err = cross_validation(lp, X, Y, 100, 10)\n",
        "\n",
        "# Check if all errors are non-zero\n",
        "assert np.all(cv_err != 0.0), \"CV error cannot be 0. ❌\"\n",
        "print(\"Mean error: \" + str(np.mean(cv_err)))\n",
        "assert np.isclose(4.997695483209219e-07, np.mean(cv_err), atol = 1e-07), \"Wrong values. ❌\"\n",
        "\n",
        "print(f\"Tests passed! ✅\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_V7ovAGTKVd"
      },
      "source": [
        "# Experiments\n",
        "\n",
        "In this section, we will run three experiments on the different algorithms we implemented above. We provide the data in the `Data` section, and then follow with the three experiments and their descriptions. You will need to analyze and understand the first two experiments for the written portion of this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiM8frTGVQ3A"
      },
      "source": [
        "## Data\n",
        "\n",
        "This section creates the datasets we will use in our comparisons. Feel free to play with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGT-ta4EWcWE"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def unit_normalize_columns(df):\n",
        "    \"\"\"\n",
        "    Normalizes each column in the DataFrame to the range [0, 1].\n",
        "\n",
        "    Args:\n",
        "    df (pandas.DataFrame): The DataFrame to normalize.\n",
        "\n",
        "    Modifies:\n",
        "    df: The DataFrame is modified in place with normalized columns.\n",
        "    \"\"\"\n",
        "    for column in df.columns:\n",
        "        min_val = df[column].min()\n",
        "        max_val = df[column].max()\n",
        "        # Avoid division by zero in case all values in the column are the same\n",
        "        if max_val != min_val:\n",
        "            df[column] = (df[column] - min_val) / (max_val - min_val)\n",
        "        else:\n",
        "            df[column] = 0  # or df[column] = 1 based on how you want to handle this case\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Liw3OT1kXQo6"
      },
      "source": [
        "### [Boston Housing dataset](https://www.kaggle.com/vikrishnan/boston-house-prices)\n",
        "\n",
        "The Boston Housing dataset is a dataset from the UCI Machine Learning Repository. It contains information collected by the U.S Census Service concerning housing in the area of Boston Mass, published in 1978. This dataset includes attributes like per capita crime rate, average number of rooms per dwelling, accessibility to highways, and a median value of owner-occupied homes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WxYfPG0XDJI"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Reading the CSV file with custom column names\n",
        "names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
        "housing_data = pd.read_csv(\"housing.csv\", delim_whitespace=True, names=names)\n",
        "\n",
        "# Normalize the data using the existing function\n",
        "housing_data = unit_normalize_columns(housing_data)\n",
        "\n",
        "housing_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi-8B76zbZZE"
      },
      "source": [
        "### [SUSY dataset](https://archive.ics.uci.edu/ml/datasets/SUSY)\n",
        "\n",
        "The SUSY dataset consists of 5 million samples of a signal process that produces supersymmetric particles in proton-proton collisions. It is used in particle physics and machine learning research to distinguish between a signal process and a background process. The dataset contains 18 features, with the first column being the label (1 for the signal, 0 for the background) and the other 17 features being kinematic properties measured by the particle detectors in the accelerator.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW27Ap4SXC3N"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Read the SUSY dataset\n",
        "susy_dataset = pd.read_csv(\"susysubset.csv\", header=None)\n",
        "\n",
        "# Normalize the dataset using the existing function\n",
        "susy_dataset = unit_normalize_columns(susy_dataset)\n",
        "susy_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5ebuOJShNxm"
      },
      "source": [
        "### Highly Correlated dataset\n",
        "\n",
        "This dataset is similar to the examples found in the original\n",
        "[Lasso paper](https://rss.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2517-6161.1996.tb02080.x). This dataset simulates heavily correlated data. Below we will use this to test `OLS` (Ordinary Least Squares), `Ridge`, and `Lasso` regression techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmSP_OvUXCkv"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def simulate_dataset(rho, N):\n",
        "    s = 8\n",
        "    # Create the covariance matrix\n",
        "    Sigma = np.array([[rho**abs(i - j) for i in range(s)] for j in range(s)])\n",
        "    # Create a multivariate normal distribution\n",
        "    mv_g = multivariate_normal(mean=np.zeros(s), cov=Sigma)\n",
        "\n",
        "    # Coefficients\n",
        "    beta = np.array([1, 0, 0, 1.5, 1, 0, 0, 1])\n",
        "    # Standard deviation of the noise\n",
        "    sigma = 3\n",
        "\n",
        "    # Generate data points\n",
        "    X = mv_g.rvs(N)\n",
        "    # Generate response variable\n",
        "    Y = X@beta + sigma * np.random.randn(N)\n",
        "\n",
        "    return X, Y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxL5pLmRhzV6"
      },
      "source": [
        "## Plotting our data\n",
        "\n",
        "The `plot_data` function produces two plots that can be displayed horizontally or vertically. The left or top plot is a box plot over the cross-validation (CV) errors, while the right or bottom plot is a bar graph displaying average CV errors with standard error bars. This function will be used for all the experiments, and you should use this to finish your written experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3Z5SeG5hXwB"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def plot_data(algs, errs):\n",
        "    \"\"\"\n",
        "    Generates a box plot and a bar graph to display MSE errors.\n",
        "\n",
        "    Args:\n",
        "    algs (list): List of algorithm names.\n",
        "    errs (list of lists): List containing lists of errors for each algorithm.\n",
        "    vert (bool): If True, plots are displayed vertically. Otherwise, horizontally.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Ensure errs is a 2D array/list\n",
        "    errs = np.array(errs)\n",
        "\n",
        "    # Standard error calculation\n",
        "    stderr = lambda x: np.sqrt(np.var(x) / len(x))\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    mean_errs = [np.mean(err) for err in errs]\n",
        "    std_errs = [stderr(err) for err in errs]\n",
        "\n",
        "\n",
        "    # Creating the box plot and bar graph\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))   # 1 row, 2 columns\n",
        "\n",
        "    # Box plot\n",
        "    axs[0].boxplot(errs.T, vert=True, patch_artist=True, showfliers=True, labels=algs)\n",
        "    axs[0].set_ylabel('MSE')\n",
        "\n",
        "    # Bar graph\n",
        "    axs[1].bar(algs, mean_errs, yerr=std_errs, capsize=5)\n",
        "    axs[1].set_ylabel('MSE' if True else '')\n",
        "\n",
        "    # Adjusting layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show the plots\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5tO4TJzkJf8"
      },
      "source": [
        "## OLS, Ridge, and Lasso\n",
        "\n",
        "We will compare OLS, Ridge, and Lasso on simulated data mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfTjzPFKkI51"
      },
      "source": [
        "Below we use two plot types to compare the the MSE with 20 training samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHEr4HtnhXdI"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ols_settings = {\n",
        "    \"ρ\": 0.7,\n",
        "    \"k\": 100,\n",
        "    \"N\": 20\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNeg1_pUkTKk"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ρ, N, k = ols_settings['ρ'], ols_settings['N'], ols_settings['k']\n",
        "algs_ols = ['OLS', 'Ridge', 'Lasso']\n",
        "\n",
        "np.random.seed(5)\n",
        "\n",
        "\n",
        "n_features = 8\n",
        "\n",
        "errs = [[],[],[]]\n",
        "for i in range(k):\n",
        "    # Simulating 30 samples\n",
        "    sim_X, sim_Y = simulate_dataset(ρ, 30)\n",
        "\n",
        "    # Train test split\n",
        "    train_X = sim_X[:N]\n",
        "    test_X = sim_X[N:]\n",
        "\n",
        "    train_Y = sim_Y[:N]\n",
        "    test_Y = sim_Y[N:]\n",
        "\n",
        "    # Ordinary linear Regression\n",
        "    # Using rigde with λ=0\n",
        "    λ=0\n",
        "    ols = Ridge(λ)\n",
        "    m = LinearModel(n_features, 1)\n",
        "    train_ridge(ols, m, train_X, train_Y)\n",
        "    err = np.mean(np.square(test_X@m.W - test_Y))\n",
        "    errs[0].append(err)\n",
        "\n",
        "    # Ridge\n",
        "    λ=0.5\n",
        "    ols = Ridge(λ)\n",
        "    m = LinearModel(n_features, 1)\n",
        "    train_ridge( ols, m, train_X, train_Y)\n",
        "    err = np.mean(np.square(test_X@m.W - test_Y))\n",
        "    m2 = m.W\n",
        "    errs[1].append(err)\n",
        "\n",
        "    # Lasso\n",
        "    λ = 0.5\n",
        "    τ = 0.0005\n",
        "    ols = Lasso(λ, τ)\n",
        "    m = LinearModel(n_features, 1)\n",
        "    train_lasso( ols, m, train_X, train_Y)\n",
        "    err = np.mean(np.square(np.dot(test_X, m.W) - np.atleast_2d(test_Y).T))\n",
        "    errs[2].append(err)\n",
        "\n",
        "\n",
        "plot_data(algs_ols, np.array(errs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BmLsG-QlMFI"
      },
      "source": [
        "## Non-linear feature transforms\n",
        "\n",
        "We will compare linear to non-linear models using the [Boston Housing dataset](https://www.kaggle.com/vikrishnan/boston-house-prices). We compare a linear representation, cosine similarity with random prototypes, RBF kernels with random prototypes, and RBF kernels with L1 selection. We use cross validation with `k folds=50` and `train_size=450`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWwnnI-ZlDtZ"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "algs = [\"Linear\", \"Cos-Rand\", \"RBF-Rand\", \"RBF-L1\"]\n",
        "\n",
        "np.random.seed(43)\n",
        "\n",
        "# Convert to NumPy array\n",
        "housing_data_np = housing_data.to_numpy()\n",
        "\n",
        "# X is all rows, columns 1 to the second-to-last column (exclusive of the last column)\n",
        "X = housing_data_np[:, :-1]\n",
        "\n",
        "# Y is all rows, last column\n",
        "Y = housing_data_np[:, -1]\n",
        "\n",
        "errs = []\n",
        "\n",
        "batch_size = 256\n",
        "n_features = 13\n",
        "train_size = 475\n",
        "k_folds = 50\n",
        "learning_rate = 0.01\n",
        "epochs = 3\n",
        "\n",
        "# Normal GD\n",
        "GD =  GDLearningProblem(\n",
        "        MiniBatchGD(batch_size),\n",
        "        LinearModel(n_features, 1),\n",
        "        ConstantLR(learning_rate),\n",
        "        MSE())\n",
        "\n",
        "cv_err = cross_validation(GD, X, Y, epochs, k_folds, train_size=train_size)\n",
        "errs.append(cv_err)\n",
        "\n",
        "\n",
        "# Cosine transformation\n",
        "GD =  GDLearningProblem(\n",
        "        MiniBatchGD(batch_size),\n",
        "        LinearModel(n_features, 1),\n",
        "        ConstantLR(learning_rate),\n",
        "        MSE())\n",
        "\n",
        "km = KernelModel(cosine_similarity(), RandomPrototypes(n_features).select_prototypes( cosine_similarity , X , Y ))\n",
        "gf = lambda x: [km.kern(x, c) for c in km.prototypes]\n",
        "feats = np.vstack([gf(x) for x in X])\n",
        "\n",
        "cv_err = cross_validation(GD, feats, Y, epochs, k_folds, train_size=train_size)\n",
        "errs.append(cv_err)\n",
        "\n",
        "\n",
        "# RBF transformation\n",
        "σ = 3.0\n",
        "GD =  GDLearningProblem(\n",
        "        MiniBatchGD(batch_size),\n",
        "        LinearModel(n_features, 1),\n",
        "        ConstantLR(learning_rate),\n",
        "        MSE())\n",
        "\n",
        "km = KernelModel(RBF(σ), RandomPrototypes(n_features).select_prototypes(RBF(σ) , X , Y ))\n",
        "gf = lambda x: [km.kern(x, c) for c in km.prototypes]\n",
        "feats = np.vstack([gf(x) for x in X])\n",
        "\n",
        "cv_err = cross_validation(GD, feats, Y, epochs, k_folds, train_size=train_size)\n",
        "errs.append(cv_err)\n",
        "\n",
        "\n",
        "np.random.seed(17)\n",
        "\n",
        "# L1Prototypes\n",
        "# Reducing the number of features to 10\n",
        "new_n = 10\n",
        "λ = 0.5\n",
        "τ = 0.9\n",
        "GD =  GDLearningProblem(\n",
        "        MiniBatchGD(batch_size),\n",
        "        LinearModel(new_n, 1),\n",
        "        ConstantLR(learning_rate),\n",
        "        MSE())\n",
        "\n",
        "km = KernelModel(RBF(σ), prototypes = L1Prototypes(λ, τ, new_n, n_features).select_prototypes(RBF(σ) , X ,Y ) , prototype_selection_strategy=L1Prototypes(λ, τ, new_n, n_features) )\n",
        "gf = lambda x: [km.kern(x, c) for c in km.prototypes]\n",
        "feats = np.vstack([gf(x) for x in X])\n",
        "\n",
        "cv_err = cross_validation(GD, feats, Y, epochs, k_folds, train_size=train_size)\n",
        "errs.append(cv_err)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plot_data(algs, errs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gAfQfHXpRYM"
      },
      "source": [
        "\n",
        "## Learning Rate Adaptation\n",
        "\n",
        "We will compare the different learning rate algorithms on a subset of the [Susy dataset](https://archive.ics.uci.edu/ml/datasets/SUSY). We will be predicting the first component."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFObgMOgpa_X"
      },
      "source": [
        "In this experiment we compare constant learning rates and RMSProp with cross validation with `k folds=10` and `train_size=95000`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo1CEpNvXYyQ"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "susy_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8b9uGeIpHRz"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "algs_lr = [\"ConstantLR\", \"RMSProp\"]\n",
        "\n",
        "np.random.seed(34)\n",
        "\n",
        "susy_dataset_np = susy_dataset.to_numpy()\n",
        "\n",
        "# X is all rows, columns 1 to the second-to-last column\n",
        "X = susy_dataset_np[:, 1:]\n",
        "\n",
        "# Y is all rows, first\n",
        "Y = susy_dataset_np[:, 0]\n",
        "\n",
        "train_size = 95000\n",
        "k_folds = 10\n",
        "epochs = 1\n",
        "batch_size = 512\n",
        "n_features = 8\n",
        "learning_rate = 0.01\n",
        "decay_parameter = 0.9\n",
        "\n",
        "lr_adapt_problems = [\n",
        "    GDLearningProblem(\n",
        "        MiniBatchGD(batch_size),\n",
        "        LinearModel(n_features, 1),\n",
        "        ConstantLR(learning_rate),\n",
        "        MSE()),\n",
        "    GDLearningProblem(\n",
        "        MiniBatchGD(batch_size),\n",
        "        LinearModel(n_features, 1),\n",
        "        RMSProp(learning_rate, decay_parameter),\n",
        "        MSE())\n",
        "]\n",
        "\n",
        "errs = []\n",
        "for idx, problems in enumerate(lr_adapt_problems):\n",
        "    cv_err = cross_validation(problems, X, Y, epochs, k_folds, train_size=train_size)\n",
        "    errs.append(cv_err)\n",
        "\n",
        "plot_data(algs_lr, errs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "env (3.10.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
